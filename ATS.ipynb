{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Satish-970/ATS_Checker_Job-Description/blob/main/ATS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBKZopwuicAa"
      },
      "source": [
        "# ATS Resume Matcher: Your Guide to a Better Resume\n",
        "\n",
        "This tool evaluates how well your resume matches a job description, providing an ATS score, keyword analysis, and suggestions for improvement. It supports resume uploads (PDF/DOCX) and job descriptions via text input or URL scraping.\n",
        "\n",
        "**Features**:\n",
        "- Upload resume in PDF or DOCX format.\n",
        "- Provide job description via text or URL (scrapes job posting from websites).\n",
        "- Get ATS match score, keyword overlap, and improvement suggestions.\n",
        "- Perform grammar and spelling checks if no job description is provided.\n",
        "- Visualize results with charts.\n",
        "\n",
        "**How to Run**:\n",
        "1. Run the first cell to install dependencies.\n",
        "2. Run the second cell to set up Java for grammar checking.\n",
        "3. Run the third cell to define functions.\n",
        "4. Run the fourth cell to start the checker, upload your resume, and input the job description (text or URL).\n",
        "\n",
        "**Notes**:\n",
        "- Use text-based (not scanned) PDF/DOCX files for accurate extraction.\n",
        "- For URLs, ensure the job posting is publicly accessible. Some dynamic websites may require manual text input.\n",
        "- No sign-in required; files are uploaded locally and deleted after analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rA7obNYnhCJE"
      },
      "source": [
        "# Step 1: Install and Import Libraries\n",
        "\n",
        "# Install necessary libraries\n",
        "!pip install spacy PyPDF2 python-docx scikit-learn matplotlib language-tool-python requests beautifulsoup4 selenium\n",
        "!python -m spacy download en_core_web_sm\n",
        "!apt-get update && apt-get install -y chromium-chromedriver\n",
        "\n",
        "# Import libraries\n",
        "import spacy\n",
        "import PyPDF2\n",
        "from docx import Document\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "import os\n",
        "import language_tool_python\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "import time\n",
        "\n",
        "# Set up Selenium for dynamic content\n",
        "def setup_selenium():\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "    try:\n",
        "        driver = webdriver.Chrome(options=chrome_options)\n",
        "        return driver\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up Selenium: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"Setup complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AfpHzso_r3fY"
      },
      "source": [
        "# Step 2: Install Java (required for LanguageTool)\n",
        "!apt-get update\n",
        "!apt-get install -y openjdk-17-jre-headless\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2ShK99ZUi_PK"
      },
      "source": [
        "# Step 3: Define Core Functions\n",
        "\n",
        "# Load the spaCy model\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "except OSError:\n",
        "    print(\"Downloading spaCy model...\")\n",
        "    !python -m spacy download en_core_web_sm\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Initialize LanguageTool for grammar and spell checking\n",
        "try:\n",
        "    tool = language_tool_python.LanguageTool('en-US')\n",
        "except Exception as e:\n",
        "    print(f\"Error initializing LanguageTool: {e}\")\n",
        "    tool = None\n",
        "\n",
        "# Function to extract text from PDF\n",
        "def extract_pdf_text(pdf_path):\n",
        "    text = ''\n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            reader = PyPDF2.PdfReader(file)\n",
        "            for page in reader.pages:\n",
        "                extracted_page_text = page.extract_text()\n",
        "                if extracted_page_text:\n",
        "                    text += extracted_page_text + ' '\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from PDF: {e}\")\n",
        "        return \"\"\n",
        "    return text.strip()\n",
        "\n",
        "# Function to extract text from DOCX\n",
        "def extract_docx_text(docx_path):\n",
        "    text = ''\n",
        "    try:\n",
        "        doc = Document(docx_path)\n",
        "        for paragraph in doc.paragraphs:\n",
        "            text += paragraph.text + ' '\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting text from DOCX: {e}\")\n",
        "        return \"\"\n",
        "    return text.strip()\n",
        "\n",
        "# Function to extract text from uploaded resume\n",
        "def extract_resume_text(file_path):\n",
        "    file_extension = file_path.lower().split('.')[-1]\n",
        "    if file_extension == 'pdf':\n",
        "        return extract_pdf_text(file_path)\n",
        "    elif file_extension in ['docx', 'doc']:\n",
        "        return extract_docx_text(file_path)\n",
        "    else:\n",
        "        print(\"Unsupported file format. Please upload PDF or DOCX files only.\")\n",
        "        return \"\"\n",
        "\n",
        "# Function to extract text from a webpage\n",
        "def extract_text_from_url(url):\n",
        "    # Try Selenium for dynamic content\n",
        "    driver = setup_selenium()\n",
        "    if driver:\n",
        "        try:\n",
        "            driver.get(url)\n",
        "            time.sleep(3)  # Allow page to load\n",
        "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
        "            driver.quit()\n",
        "        except Exception as e:\n",
        "            print(f\"Selenium failed: {e}\")\n",
        "            driver.quit()\n",
        "            soup = None\n",
        "    else:\n",
        "        soup = None\n",
        "\n",
        "    # Fallback to requests/BeautifulSoup for static content\n",
        "    if not soup:\n",
        "        try:\n",
        "            response = requests.get(url, timeout=10)\n",
        "            response.raise_for_status()\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error fetching job description from URL: {e}\")\n",
        "            return \"\"\n",
        "\n",
        "    # Remove scripts, styles, and non-content tags\n",
        "    for script in soup([\"script\", \"style\", \"header\", \"footer\", \"nav\", \"aside\"]):\n",
        "        script.decompose()\n",
        "    # Target job description-specific elements (improve specificity)\n",
        "    job_sections = soup.find_all(['div', 'section', 'article'], class_=['job-description', 'job-details', 'description', 'content'])\n",
        "    if job_sections:\n",
        "        text = ' '.join([element.get_text(strip=True) for element in job_sections])\n",
        "    else:\n",
        "        text = ' '.join([element.get_text(strip=True) for element in soup.find_all(['p', 'div', 'li', 'h1', 'h2', 'h3'])])\n",
        "    return text.strip() if text else \"\"\n",
        "\n",
        "# Function to extract keywords\n",
        "def extract_keywords(text):\n",
        "    doc = nlp(text.lower())\n",
        "    keywords = set()\n",
        "\n",
        "    # Expanded list of technical and professional skills\n",
        "    tech_skills = {\n",
        "        'python', 'java', 'javascript', 'sql', 'html', 'css', 'react', 'angular', 'vue', 'node.js',\n",
        "        'django', 'flask', 'spring', 'hibernate', 'mongodb', 'postgresql', 'mysql', 'oracle', 'aws',\n",
        "        'azure', 'gcp', 'docker', 'kubernetes', 'jenkins', 'git', 'github', 'gitlab', 'agile',\n",
        "        'scrum', 'kanban', 'jira', 'confluence', 'tensorflow', 'pytorch', 'keras', 'pandas',\n",
        "        'numpy', 'scipy', 'matplotlib', 'seaborn', 'tableau', 'powerbi', 'excel', 'r', 'scala',\n",
        "        'spark', 'hadoop', 'kafka', 'elasticsearch', 'redis', 'graphql', 'rest', 'api',\n",
        "        'microservices', 'devops', 'ci/cd', 'linux', 'windows', 'macos', 'bash', 'powershell',\n",
        "        'communication', 'leadership', 'teamwork', 'management', 'analytics', 'problem-solving',\n",
        "        'debugging', 'testing', 'automation', 'typescript', 'ruby', 'php', 'go', 'rust', 'swift',\n",
        "        'kotlin', 'ansible', 'terraform', 'sql server', 'nosql', 'etl', 'data warehousing',\n",
        "        'blockchain', 'ai', 'ml', 'nlp', 'computer vision', 'data visualization'\n",
        "    }\n",
        "\n",
        "    # Extract nouns, proper nouns, and technical skills\n",
        "    for token in doc:\n",
        "        if token.pos_ in ['NOUN', 'PROPN'] and len(token.text) > 2 and token.text.isalpha():\n",
        "            keywords.add(token.text)\n",
        "        elif token.text in tech_skills:\n",
        "            keywords.add(token.text)\n",
        "\n",
        "    # Expanded multi-word skills\n",
        "    text_lower = text.lower()\n",
        "    multi_word_skills = [\n",
        "        'machine learning', 'data analysis', 'data science', 'project management',\n",
        "        'artificial intelligence', 'deep learning', 'natural language processing',\n",
        "        'computer vision', 'big data', 'business intelligence', 'data mining',\n",
        "        'software development', 'web development', 'mobile development', 'full stack',\n",
        "        'front end', 'back end', 'database management', 'cloud computing',\n",
        "        'cyber security', 'network security', 'quality assurance', 'user experience',\n",
        "        'user interface', 'api development', 'data engineering', 'devsecops',\n",
        "        'agile methodology', 'software engineering', 'system administration'\n",
        "    ]\n",
        "\n",
        "    for skill in multi_word_skills:\n",
        "        if skill in text_lower:\n",
        "            keywords.add(skill)\n",
        "\n",
        "    return keywords\n",
        "\n",
        "# Function to calculate ATS score\n",
        "def calculate_ats_score(resume_text, job_description):\n",
        "    if not resume_text or not job_description:\n",
        "        print(\"Error: Empty resume or job description text.\")\n",
        "        return 0.0\n",
        "    documents = [resume_text, job_description]\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        stop_words='english',\n",
        "        ngram_range=(1, 2),\n",
        "        max_features=1000,\n",
        "        lowercase=True\n",
        "    )\n",
        "    try:\n",
        "        tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])[0][0]\n",
        "        return similarity * 100\n",
        "    except Exception as e:\n",
        "        print(f\"Error calculating ATS score: {e}\")\n",
        "        return 0.0\n",
        "\n",
        "# Function to provide improvement suggestions\n",
        "def get_suggestions(resume_keywords, job_keywords):\n",
        "    missing = job_keywords - resume_keywords\n",
        "    if missing:\n",
        "        missing_list = sorted(list(missing))[:10]\n",
        "        return f\"Consider adding these keywords to your resume: {', '.join(missing_list)}\"\n",
        "    return \"Excellent! Your resume contains all the key skills from the job description.\"\n",
        "\n",
        "# Function to provide score interpretation\n",
        "def get_score_feedback(score):\n",
        "    if score >= 80:\n",
        "        return \"Excellent match! Your resume aligns very well with this job.\"\n",
        "    elif score >= 65:\n",
        "        return \"Good match! Minor improvements could boost your score.\"\n",
        "    elif score >= 50:\n",
        "        return \"Moderate match. Review suggestions to improve alignment.\"\n",
        "    elif score >= 35:\n",
        "        return \"Below average match. Consider significant improvements.\"\n",
        "    else:\n",
        "        return \"Low match. Major revisions recommended to align with job requirements.\"\n",
        "\n",
        "# Function to visualize the score\n",
        "def visualize_score(score):\n",
        "    if score == 0.0:\n",
        "        print(\"No visualization generated due to invalid ATS score.\")\n",
        "        return\n",
        "    # Color coding based on score ranges\n",
        "    if score >= 80:\n",
        "        color = 'green'\n",
        "        performance = 'Excellent'\n",
        "    elif score >= 65:\n",
        "        color = 'lightgreen'\n",
        "        performance = 'Good'\n",
        "    elif score >= 50:\n",
        "        color = 'orange'\n",
        "        performance = 'Moderate'\n",
        "    elif score >= 35:\n",
        "        color = 'red'\n",
        "        performance = 'Below Average'\n",
        "    else:\n",
        "        color = 'darkred'\n",
        "        performance = 'Low'\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    bars = plt.bar(['ATS Match Score'], [score], color=color, alpha=0.8, width=0.6)\n",
        "\n",
        "    plt.ylim(0, 100)\n",
        "    plt.ylabel('Match Percentage (%)', fontsize=12)\n",
        "    plt.title('Resume ATS Match Analysis', fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.text(0, score + 2, f'{score:.1f}%\\n({performance})',\n",
        "             ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
        "\n",
        "    plt.axhline(y=80, color='green', linestyle='--', alpha=0.3, label='Excellent (80%+)')\n",
        "    plt.axhline(y=65, color='lightgreen', linestyle='--', alpha=0.3, label='Good (65%+)')\n",
        "    plt.axhline(y=50, color='orange', linestyle='--', alpha=0.3, label='Moderate (50%+)')\n",
        "    plt.axhline(y=35, color='red', linestyle='--', alpha=0.3, label='Below Average (35%+)')\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Function to visualize keyword overlap\n",
        "def visualize_keyword_overlap(resume_keywords, job_keywords):\n",
        "    resume_count = len(resume_keywords)\n",
        "    job_count = len(job_keywords)\n",
        "    overlap_count = len(resume_keywords & job_keywords)\n",
        "\n",
        "    ```chartjs\n",
        "    {\n",
        "        \"type\": \"venn\",\n",
        "        \"data\": {\n",
        "            \"labels\": [\"Resume Keywords\", \"Job Description Keywords\", \"Overlap\"],\n",
        "            \"datasets\": [{\n",
        "                \"data\": [\n",
        "                    {\"sets\": [0], \"size\": resume_count - overlap_count},\n",
        "                    {\"sets\": [1], \"size\": job_count - overlap_count},\n",
        "                    {\"sets\": [0, 1], \"size\": overlap_count}\n",
        "                ],\n",
        "                \"backgroundColor\": [\"#36A2EB\", \"#FF6384\", \"#FFCE56\"]\n",
        "            }]\n",
        "        },\n",
        "        \"options\": {\n",
        "            \"title\": {\n",
        "                \"display\": true,\n",
        "                \"text\": \"Keyword Overlap Analysis\"\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "    ```\n",
        "\n",
        "# Function to perform general resume check\n",
        "def perform_general_check(resume_text, file_name):\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"GENERAL RESUME HEALTH CHECK RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Grammar and Spelling Analysis\n",
        "    if tool:\n",
        "        print(\"\\nGrammar and Spelling Analysis:\")\n",
        "        matches = tool.check(resume_text)\n",
        "        if matches:\n",
        "            print(f\"- Found {len(matches)} potential issue(s). Review these suggestions:\\n\")\n",
        "            for i, match in enumerate(matches[:5]):\n",
        "                print(f\"  {i+1}. Issue: '{match.ruleId}', Suggestion: '{match.replacements}', Context: '{match.context}'\")\n",
        "            if len(matches) > 5:\n",
        "                print(\"  ... and more. Please proofread your resume carefully.\")\n",
        "        else:\n",
        "            print(\"- No major grammar or spelling issues detected. Great job! ðŸ‘\")\n",
        "    else:\n",
        "        print(\"- Grammar checking unavailable due to LanguageTool initialization failure.\")\n",
        "\n",
        "    # Formatting and Structure Analysis\n",
        "    print(\"\\nFormatting and Structure Tips:\")\n",
        "    resume_lower = resume_text.lower()\n",
        "    sections = ['experience', 'skills', 'education', 'projects', 'summary']\n",
        "    found_sections = [sec for sec in sections if sec in resume_lower]\n",
        "\n",
        "    if len(found_sections) >= 3:\n",
        "        print(f\"- Your resume uses standard section headings ({', '.join(found_sections)}), which is great for ATS parsing. âœ…\")\n",
        "    else:\n",
        "        print(f\"- Consider using standard headings like 'Experience', 'Skills', and 'Education'. Missing: {', '.join(list(set(sections) - set(found_sections)))}.\")\n",
        "\n",
        "    if any(keyword in resume_lower for keyword in ['table', 'column', 'image']):\n",
        "        print(\"- Warning: Complex formatting (tables, columns, images) detected. These may cause ATS parsing issues.\")\n",
        "    else:\n",
        "        print(\"- Your resume appears to have a clean, ATS-friendly format. ðŸ‘\")\n",
        "\n",
        "    # Keyword and Content Analysis\n",
        "    print(\"\\nKeyword & Content Recommendations:\")\n",
        "    action_verbs = ['managed', 'developed', 'created', 'implemented', 'analyzed', 'led', 'designed', 'optimized', 'improved']\n",
        "    found_verbs = [verb for verb in action_verbs if verb in resume_lower]\n",
        "\n",
        "    if len(found_verbs) > 5:\n",
        "        print(\"- Good use of action verbs to describe your experience.\")\n",
        "    else:\n",
        "        print(f\"- Use stronger action verbs like: {', '.join(action_verbs[:5])}.\")\n",
        "\n",
        "    if any(char.isdigit() and '%' in resume_text for char in resume_text) or any(char.isdigit() and '$' in resume_text for char in resume_text):\n",
        "        print(\"- Quantifiable results found, showcasing your impact. Keep it up! ðŸ’ª\")\n",
        "    else:\n",
        "        print(\"- Add quantifiable results (e.g., 'Increased sales by 15%') for stronger impact.\")\n",
        "\n",
        "    resume_keywords = extract_keywords(resume_text)\n",
        "    print(f\"- Your resume contains {len(resume_keywords)} keywords. Ensure a mix of technical and soft skills.\")\n",
        "\n",
        "    # Cleanup\n",
        "    if os.path.exists(file_name):\n",
        "        os.remove(file_name)\n",
        "        print(f\"\\nTemporary file '{file_name}' removed.\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Analysis Complete! Good luck! ðŸŽ‰\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "print(\"All functions defined successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "main_checker"
      },
      "source": [
        "# Step 4: Run the ATS Checker\n",
        "\n",
        "def run_ats_checker():\n",
        "    print(\"ATS Resume Checker\")\n",
        "    print(\"=\" * 50)\n",
        "    print(\"This tool analyzes your resume against a job description or performs a general health check.\")\n",
        "    print(\"Supported formats: PDF, DOCX, DOC\")\n",
        "    print(\"\\nStep 1: Upload your resume file\")\n",
        "    print(\"Click 'Choose Files' below to select your resume...\")\n",
        "\n",
        "    # Upload resume file\n",
        "    try:\n",
        "        uploaded_files = files.upload()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during file upload: {e}\")\n",
        "        return\n",
        "\n",
        "    if not uploaded_files:\n",
        "        print(\"No file uploaded. Please try again.\")\n",
        "        return\n",
        "\n",
        "    file_name = list(uploaded_files.keys())[0]\n",
        "    print(f\"Successfully uploaded: {file_name}\")\n",
        "\n",
        "    # Extract text from resume\n",
        "    try:\n",
        "        resume_text = extract_resume_text(file_name)\n",
        "        if not resume_text or len(resume_text.strip()) < 100:\n",
        "            print(\"Warning: Resume text is too short or unreadable. Ensure it's a text-based PDF/DOCX.\")\n",
        "            if os.path.exists(file_name):\n",
        "                os.remove(file_name)\n",
        "            return\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading file: {e}\")\n",
        "        print(\"Please upload a valid PDF or DOCX file.\")\n",
        "        if os.path.exists(file_name):\n",
        "            os.remove(file_name)\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 50)\n",
        "    print(\"Step 2: Provide the job description\")\n",
        "    print(\"- Enter a URL to a job posting (e.g., https://example.com/job) and press Enter.\")\n",
        "    print(\"- Or, leave the URL blank and press Enter, then paste the job description text in the next prompt.\")\n",
        "    print(\"- Or, leave both blank (press Enter twice) for a general resume health check.\")\n",
        "\n",
        "    job_desc_url = input(\"\\nJob Description URL (leave blank to paste text): \")\n",
        "    job_desc = \"\"\n",
        "\n",
        "    if job_desc_url.strip():\n",
        "        print(f\"\\nFetching job description from: {job_desc_url}\")\n",
        "        job_desc = extract_text_from_url(job_desc_url)\n",
        "        if not job_desc:\n",
        "            print(\"Failed to extract job description from URL. Try pasting the job description text.\")\n",
        "            job_desc = input(\"\\nJob Description (paste here, or leave blank for health check): \")\n",
        "    else:\n",
        "        job_desc = input(\"\\nJob Description (paste here, or leave blank for health check): \")\n",
        "\n",
        "    if not job_desc.strip():\n",
        "        print(\"\\nNo job description provided. Performing general resume health check...\")\n",
        "        perform_general_check(resume_text, file_name)\n",
        "    else:\n",
        "        if len(job_desc.strip()) < 50:\n",
        "            print(\"Warning: Job description is very short. Consider providing a complete job posting.\")\n",
        "\n",
        "        print(\"\\nAnalyzing resume against job description...\")\n",
        "\n",
        "        try:\n",
        "            resume_keywords = extract_keywords(resume_text)\n",
        "            job_keywords = extract_keywords(job_desc)\n",
        "            ats_score = calculate_ats_score(resume_text, job_desc)\n",
        "\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"ATS MATCH ANALYSIS RESULTS\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "            print(f\"\\nATS Match Score: {ats_score:.2f}%\")\n",
        "            print(f\"Score Category: {get_score_feedback(ats_score)}\")\n",
        "\n",
        "            print(f\"\\nKeyword Analysis:\")\n",
        "            print(f\"- Resume keywords: {len(resume_keywords)}\")\n",
        "            print(f\"- Job description keywords: {len(job_keywords)}\")\n",
        "            print(f\"- Matching keywords: {len(resume_keywords & job_keywords)}\")\n",
        "\n",
        "            matching_keywords = resume_keywords & job_keywords\n",
        "            if matching_keywords:\n",
        "                print(f\"\\nMatching skills: {', '.join(sorted(list(matching_keywords))[:15])}\")\n",
        "\n",
        "            print(f\"\\nImprovement Suggestions:\")\n",
        "            print(get_suggestions(resume_keywords, job_keywords))\n",
        "\n",
        "            visualize_score(ats_score)\n",
        "            visualize_keyword_overlap(resume_keywords, job_keywords)\n",
        "\n",
        "            print(\"\\nAdditional Tips to Boost Your Score:\")\n",
        "            if ats_score < 65:\n",
        "                print(\"- Use exact keywords from the job description.\")\n",
        "                print(\"- Add a dedicated skills section.\")\n",
        "                print(\"- Tailor experience descriptions to job requirements.\")\n",
        "                print(\"- Use industry-standard terminology.\")\n",
        "\n",
        "            print(\"- Use a simple, ATS-friendly resume format.\")\n",
        "            print(\"- Include standard headings (Experience, Skills, Education).\")\n",
        "            print(\"- Avoid images, tables, and complex formatting.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during analysis: {e}\")\n",
        "\n",
        "        finally:\n",
        "            if os.path.exists(file_name):\n",
        "                os.remove(file_name)\n",
        "                print(f\"\\nTemporary file '{file_name}' removed.\")\n",
        "\n",
        "            print(\"\\n\" + \"=\" * 60)\n",
        "            print(\"Analysis Complete! Good luck! ðŸŽ‰\")\n",
        "            print(\"=\" * 60)\n",
        "\n",
        "# Run the ATS checker\n",
        "run_ats_checker()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deploy_instructions"
      },
      "source": [
        "## Saving to GitHub\n",
        "\n",
        "To store this notebook on GitHub:\n",
        "1. Save this JSON as `ats_matcher.ipynb`.\n",
        "2. Upload to a GitHub repository (e.g., `ATS_Checker_Job-Description`).\n",
        "3. Open in Colab using the link in the first cell.\n",
        "\n",
        "**Notes**:\n",
        "- Runs in Google Colab; no Streamlit required.\n",
        "- Ensure resume files are text-based.\n",
        "- For URLs, use publicly accessible job postings. Dynamic websites may require manual text input.\n",
        "- Temporary files are deleted after analysis."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
